{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd41e683-2906-4c6c-9560-c8f5c1db2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert midi\n",
    "\n",
    "import os\n",
    "from midi2audio import FluidSynth\n",
    "fs = FluidSynth('MuseScore_General.sf2')\n",
    "for filename in os.listdir(\"midis_composersA_B\"):\n",
    "    filename = filename.strip('.mid')\n",
    "    print(filename)\n",
    "    fs.midi_to_audio(f'midis/{filename}.mid', f'midi2audio/{filename}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c013abc-b64e-44cc-84c3-a23d6d4877e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d1c13-7744-4d44-95a3-67f6e1e5566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AUDIO\n",
    "\n",
    "audio = []\n",
    "counter = 0\n",
    "\n",
    "for filename in os.listdir('data/image-data'):\n",
    "    print(filename)\n",
    "    filename, sr = lr.load(f'data/image-data/{filename}') # sample rate\n",
    "    counter += 1\n",
    "    audio.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00795901-a701-4f81-8e67-7e69f2711617",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b90d2f-1feb-49cf-9196-d6178030dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT params\n",
    "\n",
    "FRAME_SIZE = 2048\n",
    "HOP_SIZE = 342\n",
    "\n",
    "# STFT params\n",
    "\n",
    "FRAME_SIZE = 2048\n",
    "HOP_SIZE = 342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8c285-1f8d-45c1-847b-6f045e486cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Transformation Short Time Fourier Tranform (STFT)\n",
    "\n",
    "transformed_audio = []\n",
    "\n",
    "for song in audio:\n",
    "    stft = lr.stft(song, n_fft = FRAME_SIZE-1, hop_length = HOP_SIZE)\n",
    "    stft = np.abs(stft) ** 2\n",
    "    transformed_audio.append(stft)\n",
    "\n",
    "# First Transformation Short Time Fourier Tranform (STFT)\n",
    "\n",
    "transformed_audio = []\n",
    "\n",
    "for song in padded_audio_pieces:\n",
    "    stft = lr.stft(song, n_fft = FRAME_SIZE-1, hop_length = HOP_SIZE)\n",
    "    stft = np.abs(stft) ** 2\n",
    "    transformed_audio.append(stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ccef6-d9c8-4092-8407-b84d242cf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAD AUDIO \n",
    "\n",
    "padded_audio_pieces = []\n",
    "\n",
    "for piece in audio:\n",
    "    padded_audio_piece = lr.util.fix_length(piece, size=1500000)\n",
    "    padded_audio_pieces.append(padded_audio_piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283d59f-758c-4241-abbc-43ff9850f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_audio[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f0d8a-3e30-443f-b416-757aec41fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SCALER\n",
    "X_scaler = MinMaxScaler()\n",
    "\n",
    "# NORMALIZE AUDIO FUNCTION\n",
    "def normalize_spec(X,scaler):\n",
    "    '''\n",
    "    Input spectrogram should be in the shape of (n_samples, n_freqency_bin, n_time_steps)\n",
    "    or in the shape of (n_samples, 1, n_freqency_bin, n_time_steps)\n",
    "    '''\n",
    "    X_norm = []\n",
    "    if len(X[0].shape) == 3:\n",
    "        print(\"Images with channels\")\n",
    "        for spec in X:\n",
    "            H = spec.shape[1]; W=spec.shape[2]\n",
    "            norm = scaler.fit_transform(spec.reshape(H*W,1))\n",
    "            X_norm.append(norm.reshape(H,W))\n",
    "\n",
    "        X_norm = np.array(X_norm)    \n",
    "\n",
    "    elif len(X[0].shape) == 2:\n",
    "        print(\"Images with H and W\")\n",
    "        for spec in X:\n",
    "            H = spec.shape[0]; W=spec.shape[1]\n",
    "            norm = scaler.fit_transform(spec.reshape(H*W,1))\n",
    "            X_norm.append(norm.reshape(H,W))\n",
    "\n",
    "        X_norm = np.array(X_norm)\n",
    "\n",
    "    else:\n",
    "        print(\"shape error, please check your input\")\n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1ea10-b115-42c7-b314-442219576fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZE AUDIO\n",
    "normalized_audio = normalize_spec(transformed_log_audio, X_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a3d33-8c77-41e7-9776-023c156c76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Spectrogram\n",
    "\n",
    "def plot_spectrogram(Y, sr, hop_length, y_axis='linear'):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    lr.display.specshow(Y, \n",
    "                        sr=sr,\n",
    "                       hop_length = hop_length,\n",
    "                       x_axis='time',\n",
    "                       y_axis=y_axis)\n",
    "    plt.colorbar(format=\"%+2.f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140cf9a-60b6-42cf-a80d-b43053ec5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(transformed_audio[2],sr ,HOP_SIZE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65435625-bfc4-4f73-84c0-c819da574260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Tranformation (power to db)\n",
    "\n",
    "transformed_log_audio = []\n",
    "for stft in transformed_audio:\n",
    "    log_stft = lr.power_to_db(stft)\n",
    "    transformed_log_audio.append(log_stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f77673-7057-4eca-963a-ae9c355f130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_log_audio[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ae1b7-7b35-4bc1-a5ee-d5190dc08ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(transformed_log_audio[2], sr ,HOP_SIZE, y_axis ='linear' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d4d54-2bc2-4f6d-a694-d131a84ab593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(transformed_log_audio[2], sr ,HOP_SIZE, y_axis ='log' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944da04d-5816-40e5-bc79-b953fd2d0505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export converted audio file as numpy array ( .npy file)\n",
    "\n",
    "counter = 1\n",
    "for npy in transformed_log_audio:\n",
    "    np.save(f'../npy_files/npy_file_no{counter}', npy)\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
