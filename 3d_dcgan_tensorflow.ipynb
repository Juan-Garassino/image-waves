{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bVACspmTwm5k",
   "metadata": {
    "id": "bVACspmTwm5k"
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mZUUkiIRee_Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZUUkiIRee_Z",
    "outputId": "6f064668-82bd-4d85-b7e2-eebb1697b448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "peLoi04XajBU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "peLoi04XajBU",
    "outputId": "bb3b98ae-3bec-43be-97cc-7bd43e31ad3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "pip install pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Trya87l1z_PH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Trya87l1z_PH",
    "outputId": "5af59267-eee4-40f9-97d2-f4af0bb7afc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5b9dc0",
   "metadata": {
    "id": "bd5b9dc0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############\n",
    "## Imports ##\n",
    "#############\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "STYLE = \"#ffffff\"\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "import keras\n",
    "\n",
    "from scipy.fft import dst, dct, fft\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3-42l_sSFebc",
   "metadata": {
    "id": "3-42l_sSFebc"
   },
   "source": [
    "# VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9zQrOxkZFhJo",
   "metadata": {
    "id": "9zQrOxkZFhJo"
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "## Define the training loop ##\n",
    "##############################\n",
    "\n",
    "load_data = True\n",
    "\n",
    "n_samples = 5000\n",
    "\n",
    "void_dim = 56\n",
    "\n",
    "BUFFER_SIZE = 5000\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "noise_dim = 1024\n",
    "\n",
    "num_examples_to_generate = 1\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier) to visualize progress in the animated GIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EVpYsvtQxiHo",
   "metadata": {
    "id": "EVpYsvtQxiHo"
   },
   "source": [
    "# ELEMENTS CREATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "LWbR-jJdBeZd",
   "metadata": {
    "id": "LWbR-jJdBeZd"
   },
   "outputs": [],
   "source": [
    "class Sculptor():\n",
    "    \n",
    "    def __init__(self, void_dim,\n",
    "                 n_edge_elements,\n",
    "                 n_plane_elements,\n",
    "                 n_volume_elements,\n",
    "                 element_edge_min,\n",
    "                 element_edge_max,\n",
    "                 element_plane_min,\n",
    "                 element_plane_max,\n",
    "                 element_volume_min,\n",
    "                 element_volume_max,\n",
    "                 step,\n",
    "                 verbose):\n",
    "        \n",
    "        self.void = np.zeros((void_dim, void_dim, void_dim))\n",
    "        self.n_edge_elements = n_edge_elements\n",
    "        self.n_plane_elements = n_plane_elements\n",
    "        self.n_volume_elements = n_volume_elements\n",
    "        self.style = \"#ffffff\"\n",
    "        \n",
    "        self.element_edge_min= element_edge_min\n",
    "        self.element_edge_max = element_edge_max\n",
    "        self.element_plane_min = element_plane_min\n",
    "        self.element_plane_max = element_plane_max\n",
    "        self.element_volume_min = element_volume_min\n",
    "        self.element_volume_max = element_volume_max\n",
    "        self.step = step\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "    def return_axis(self):\n",
    "        \n",
    "        self.section = np.random.randint(low=0-1, high=self.void[0].shape[0])\n",
    "        self.axis_selection = np.random.randint(low=0, high=3)\n",
    "        \n",
    "        if self.axis_selection == 0:\n",
    "            self.working_plane = self.void[self.section,:,:]\n",
    "        elif self.axis_selection == 1:\n",
    "            self.working_plane = self.void[:,self.section,:]  \n",
    "        elif self.axis_selection == 2:\n",
    "            self.working_plane = self.void[:,:,self.section]\n",
    "        else:\n",
    "            print(\"error\")\n",
    "        return self.working_plane\n",
    "    \n",
    "    ### MAIN FUNCTIONS ###\n",
    "    \n",
    "    def add_edge(self): # element sizes\n",
    "        \n",
    "        self.working_plane = self.return_axis()\n",
    "        # selection of the axis to work on\n",
    "        if self.verbose == True:\n",
    "            print(working_plane)\n",
    "            print(\"###############################################################\")\n",
    "\n",
    "        #Variables\n",
    "        self.edge_length = random.randrange(self.element_edge_min, self.element_edge_max, self.step) # estas variables quizas no necesiten ser self!!\n",
    "        self.edge_plane = np.random.randint(low=0, high=2)\n",
    "\n",
    "        if self.edge_plane == 0:\n",
    "            self.element = np.ones(self.edge_length).reshape(self.edge_length,1)\n",
    "        else:\n",
    "            self.element = np.ones(self.edge_length).reshape(self.edge_length,1).T\n",
    "\n",
    "        # creates the element to be inserted\n",
    "        self.delta = np.array(self.working_plane.shape) - np.array(self.element.shape) \n",
    "        # finds the delta between the size of the void and the size of the element\n",
    "        top_left_corner = (coor_i, coor_j) = (np.random.randint(low=0, high=self.delta[0]) , np.random.randint(low=0, high=self.delta[1]))\n",
    "        # finds the coordinates of the top left corner\n",
    "        top_left_corner = np.array(top_left_corner)\n",
    "        # converts the result in an array\n",
    "        bottom_right_corner = np.array(top_left_corner) + np.array(self.element.shape) #- np.array([1,1]))\n",
    "        # finds the coordinates of the bottom right corner\n",
    "        self.working_plane[top_left_corner[0]:bottom_right_corner[0] , top_left_corner[1]:bottom_right_corner[1]] = self.element\n",
    "        # makes the slides using the coordinates equal to the element\n",
    "\n",
    "        if self.verbose == True:\n",
    "            print(self.working_plane)\n",
    "            print(\"###############################################################\")\n",
    "    \n",
    "    def add_plane(self): # element sizes\n",
    "        \n",
    "        self.element = None\n",
    "        self.section = None\n",
    "        self.delta = None\n",
    "        self.top_left_corner = None\n",
    "        self.bottom_right_corner = None\n",
    "        self.working_plane = self.return_axis()\n",
    "        if self.verbose == True:\n",
    "            print(self.working_plane)\n",
    "            print(\"###############################################################\")\n",
    "\n",
    "        #Variables\n",
    "        self.element = np.ones((random.randrange(self.element_plane_min, self.element_plane_max, self.step), random.randrange(self.element_plane_min, self.element_plane_max, self.step)))\n",
    "        # creates the element to be inserted\n",
    "        self.delta = np.array(self.working_plane.shape) - np.array(self.element.shape) \n",
    "        # finds the delta between the size of the void and the size of the element\n",
    "        self.top_left_corner = (coor_i, coor_j) = (np.random.randint(low=0, high=self.delta[0]) , np.random.randint(low=0, high=self.delta[1]))\n",
    "        # finds the coordinates of the top left corner\n",
    "        self.top_left_corner = np.array(self.top_left_corner)\n",
    "        # converts the result in an array\n",
    "        self.bottom_right_corner = np.array(self.top_left_corner) + np.array(self.element.shape) #- np.array([1,1]))\n",
    "        # finds the coordinates of the bottom right corner\n",
    "        self.working_plane[self.top_left_corner[0]:self.bottom_right_corner[0] , self.top_left_corner[1]:self.bottom_right_corner[1]] = self.element\n",
    "        # makes the slides using the coordinates equal to the element\n",
    "\n",
    "        if self.verbose == True:\n",
    "            self.print_information()\n",
    "            print(\"###############################################################\")\n",
    "            \n",
    "        return self.void\n",
    "    \n",
    "    def add_pipe_cantilever(self):\n",
    "        \n",
    "        self.element = None\n",
    "        self.working_plane = None\n",
    "        self.delta = None\n",
    "        self.top_left_corner = None\n",
    "        self.bottom_right_corner = None\n",
    "        self.axis_selection = np.random.randint(low=0, high=2)\n",
    "        self.shape_selection = np.random.randint(low=0, high=2)\n",
    "        self.depth = random.randrange(self.element_volume_min, self.element_volume_max, self.step)\n",
    "        \n",
    "        if self.verbose == True:\n",
    "            print(self.working_plane)\n",
    "            print(\"###############################################################\")\n",
    "            \n",
    "        self.element = np.ones((random.randrange(self.element_volume_min, self.element_volume_max, self.step), random.randrange(self.element_volume_min, self.element_volume_max, self.step)))\n",
    "        self.element = np.repeat(self.element, repeats=self.depth, axis=0).reshape((self.element.shape[0],self.element.shape[1],self.depth))\n",
    "\n",
    "        self.element_void = np.zeros((self.element.shape[0]-2, self.element.shape[1]-2))\n",
    "        self.element_void = np.repeat(self.element_void, repeats=self.depth).reshape((self.element_void.shape[0],self.element_void.shape[1],self.depth))\n",
    "\n",
    "        # element[1:-1,1:-1,:] = element_void # elegir pasar el vacio o no como parte del volumen\n",
    "        \n",
    "        self.delta = np.array(self.void.shape) - np.array(self.element.shape) # ENCONTRAR LOS NUEVOS DELTAS\n",
    "\n",
    "        corner_1 = np.array((np.random.randint(low=0, high=self.delta[0]) , np.random.randint(low=0, high=self.delta[1]), np.random.randint(low=0, high=self.delta[2])))\n",
    "        corner_2 = np.array((corner_1[0] + self.element.shape[0], corner_1[1], corner_1[2]))\n",
    "        corner_3 = np.array((corner_1[0], corner_1[1], corner_1[2] + self.element.shape[2]))\n",
    "        corner_4 = np.array((corner_1[0] + self.element.shape[0], corner_1[1], corner_1[2] + self.element.shape[2]))\n",
    "        \n",
    "        corner_5 = np.array((corner_1[0], corner_1[1] + self.element.shape[1], corner_1[2]))\n",
    "        corner_6 = np.array((corner_2[0], corner_2[1] + self.element.shape[1], corner_2[2]))\n",
    "        corner_7 = np.array((corner_3[0], corner_3[1] + self.element.shape[1], corner_3[2]))\n",
    "        corner_8 = np.array((corner_4[0], corner_4[1] + self.element.shape[1], corner_4[2]))\n",
    "        \n",
    "        # creates the floor and ceiling\n",
    "        self.void[corner_3[0]:corner_8[0], corner_3[1]:corner_8[1], corner_3[2]-1] = self.element[:,:,0]\n",
    "        self.void[corner_1[0]:corner_6[0], corner_1[1]:corner_6[1], corner_1[2]] = self.element[:,:,1]\n",
    "        \n",
    "        # creates de walls\n",
    "        if self.shape_selection ==0:\n",
    "            if self.axis_selection == 0:\n",
    "                self.void[corner_1[0], corner_1[1]:corner_7[1], corner_1[2]:corner_7[2]] = self.element[0,:,:]\n",
    "                self.void[corner_2[0]-1, corner_2[1]:corner_8[1], corner_2[2]:corner_8[2]] = self.element[1,:,:]\n",
    "            else:\n",
    "                self.void[corner_5[0]:corner_8[0], corner_5[1], corner_5[2]:corner_8[2]] = self.element[:,0,:]\n",
    "                self.void[corner_1[0]:corner_4[0], corner_1[1], corner_1[2]:corner_4[2]] = self.element[:,0,:]\n",
    "                \n",
    "        else:\n",
    "            if self.axis_selection == 0:\n",
    "                self.void[corner_1[0], corner_1[1]:corner_7[1], corner_1[2]:corner_7[2]] = self.element[0,:,:]\n",
    "                self.void[corner_5[0]:corner_8[0], corner_5[1], corner_5[2]:corner_8[2]] = self.element[:,0,:]\n",
    "            else:\n",
    "                self.void[corner_2[0]-1, corner_2[1]:corner_8[1], corner_2[2]:corner_8[2]] = self.element[1,:,:]\n",
    "                self.void[corner_1[0]:corner_4[0], corner_1[1], corner_1[2]:corner_4[2]] = self.element[:,0,:]\n",
    "        \n",
    "        if self.verbose == True:\n",
    "            self.print_information()\n",
    "            print(\"###############################################################\")\n",
    "        \n",
    "        return self.void\n",
    "    \n",
    "    def add_grill(self):\n",
    "        pass\n",
    "    \n",
    "    ### ULTILS ###\n",
    "    \n",
    "    def print_information(self):\n",
    "        print(f\"void shape is: {np.array(self.void[0].shape)}\")\n",
    "        print(f\"element shape is : {np.array(self.element.shape)}\")\n",
    "        print(f\"the axis selection is: {self.axis_selection}\")\n",
    "        print(f\"delta is: {self.delta}\")\n",
    "        print(f\"section is: {self.section}\")\n",
    "        print(f\"top left corner is: {self.top_left_corner}\")\n",
    "        print(f\"bottom right corner is: {self.bottom_right_corner}\")\n",
    "        print(f\"slices are: {self.top_left_corner[0]}:{self.bottom_right_corner[0]} and {self.top_left_corner[1]}:{self.bottom_right_corner[1]}\")\n",
    "        print(\"###############################################################\")\n",
    "    \n",
    "    def plot_sections(self):\n",
    "        sculpture = self.void\n",
    "        fig, axes = plt.subplots(ncols=6, nrows=int(np.ceil(self.void.shape[0]/6)), figsize=(25, 25), facecolor = (self.style))\n",
    "        axes = axes.ravel() # flats\n",
    "        for index in range(self.void.shape[0]):\n",
    "            axes[index].imshow(sculpture[index,:,:], cmap = \"gray\")\n",
    "            \n",
    "    def plot_sculpture(self):\n",
    "        sculpture = self.void\n",
    "        fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(25, 25), facecolor = (self.style), subplot_kw=dict(projection=\"3d\"))\n",
    "        axes = axes.ravel() # flats\n",
    "        for index in range(1):\n",
    "            axes[index].voxels(sculpture, facecolors=\"orange\", edgecolors=\"k\", linewidth=0.05)\n",
    "    \n",
    "    ### GENERATOR ###\n",
    "    \n",
    "    def generative_sculpt(self):\n",
    "        for i in range(self.n_edge_elements):\n",
    "            time.sleep(0)\n",
    "            self.axis_selection = np.random.randint(low=0, high=3)\n",
    "            self.add_edge()\n",
    "            \n",
    "        for i in range(self.n_plane_elements):\n",
    "            time.sleep(0)\n",
    "            self.axis_selection = np.random.randint(low=0, high=3)\n",
    "            self.add_plane()\n",
    "            \n",
    "        for i in range(self.n_volume_elements):\n",
    "            self.add_pipe_cantilever()\n",
    "\n",
    "        return self.void"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EkBOwVtQxrNn",
   "metadata": {
    "id": "EkBOwVtQxrNn"
   },
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "FvTawtKR0WNi",
   "metadata": {
    "id": "FvTawtKR0WNi"
   },
   "outputs": [],
   "source": [
    "if load_data:\n",
    "  os.chdir(\"/content/drive/MyDrive/data/volumetries\")\n",
    "\n",
    "  raw_data = np.load(\"raw-data-new.npy\")\n",
    "\n",
    "else:\n",
    "  os.chdir(\"/content/drive/MyDrive/data/volumetries\")\n",
    "  raw_data = []\n",
    "  count = 0\n",
    "\n",
    "  for sculpture in range(n_samples): #\n",
    "      count = count + 1\n",
    "      if count % 10 == 0:\n",
    "          print(\"\\r{0}\".format(count), end='')\n",
    "      \n",
    "      sculptor = Sculptor(void_dim = void_dim,\n",
    "                    n_edge_elements = 0,\n",
    "                    n_plane_elements = 8,\n",
    "                    n_volume_elements = 3,\n",
    "                    element_edge_min= 16,\n",
    "                    element_edge_max = 48,\n",
    "                    element_plane_min = 16,\n",
    "                    element_plane_max = 30,\n",
    "                    element_volume_min = 10,\n",
    "                    element_volume_max = 30,\n",
    "                    step = 3,\n",
    "                    verbose = False)\n",
    "      \n",
    "      sculpture = sculptor.generative_sculpt()\n",
    "      \n",
    "      raw_data.append(sculpture)\n",
    "\n",
    "  raw_data = np.asarray(raw_data).reshape((n_samples, void_dim, void_dim, void_dim, 1))\n",
    "\n",
    "  np.save(\"raw-data-new\", raw_data, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dqrFH4mHySMq",
   "metadata": {
    "id": "dqrFH4mHySMq"
   },
   "source": [
    "# MODEL GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2tX5uSVHpncG",
   "metadata": {
    "id": "2tX5uSVHpncG"
   },
   "outputs": [],
   "source": [
    "# The generator uses tf.keras.layers.Conv2DTranspose (upsampling) layers to produce an image from a seed (random noise). \n",
    "\n",
    "def make_three_dimentional_generator():\n",
    "    model = tf.keras.Sequential() # Initialize Sequential model\n",
    "    # The Sequential model is a straight line. You keep adding layers, every new layer takes the output of the previous layer. You cannot make creative graphs with branches\n",
    "    # The functoinal API Model is completely free to have as many ramifications, inputs and outputs as you need\n",
    "    model.add(layers.Dense(7*7*7*256, use_bias=False, input_shape=(noise_dim,))) # shape 100 noise vector, 7*7*256 flat layer to reshape [7,7,256] | 7 width 7 height 256 channels\n",
    "    model.add(layers.BatchNormalization()) # BatchNormalization doesn't require bias, makes the model faster and more stable\n",
    "    model.add(layers.ReLU()) # LeakyReLU\n",
    "    model.add(layers.Reshape((7, 7, 7, 256))) # reshape [7,7,256] \n",
    "    assert model.output_shape == (None, 7, 7, 7, 256) # None is the batch size\n",
    "\n",
    "    model.add(layers.Conv3DTranspose(128, (9, 9, 9), strides=(1, 1, 1), padding='same', use_bias=False)) # 128 Filters... to be the number of channels of the output, (5,5) kernel\n",
    "    assert model.output_shape == (None, 7, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Conv3DTranspose(64, (7, 7, 7), strides=(2, 2, 2), padding='same', use_bias=False)) # 128 Filters... to be the number of channels of the output, (5,5) kernel\n",
    "    assert model.output_shape == (None, 14, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Conv3DTranspose(32, (7, 7, 7), strides=(2, 2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 28, 28, 28, 32)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Conv3DTranspose(1, (5, 5, 5), strides=(2, 2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    model.add(layers.ThresholdedReLU(theta = 0))\n",
    "    assert model.output_shape == (None, 56, 56, 56, 1)\n",
    "    return model\n",
    "\n",
    "generator = make_three_dimentional_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EUsbJmKYbDgQ",
   "metadata": {
    "id": "EUsbJmKYbDgQ"
   },
   "source": [
    "# MODEL CRITIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tS5IQsNcpPI6",
   "metadata": {
    "id": "tS5IQsNcpPI6"
   },
   "outputs": [],
   "source": [
    "# The discriminator is a CNN-based image classifier it uses tf.keras.layers.Conv2D to classify images as real or fake\n",
    "\n",
    "def make_three_dimentional_critic():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv3D(32, (5, 5, 5), strides=(2, 2, 2), padding='same', input_shape=[56, 56, 56, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv3D(64, (5, 5, 5), strides=(2, 2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv3D(128, (5, 5, 5), strides=(2, 2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "discriminator = make_three_dimentional_critic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3e25a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a3e25a4",
    "outputId": "2a4281a6-bf81-4497-c60f-7aeecb6c733f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.4999786]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generator(tf.random.normal([1, noise_dim])))#[0].reshape((28,28,28,1)))\n",
    "\n",
    "print(decision) # 50 / 50 not trained, will be trained to generate positive values for real pictures and negative for generated ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vGg2S-iopOGT",
   "metadata": {
    "id": "vGg2S-iopOGT"
   },
   "source": [
    "# SUMMARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "LC8PQRa1bZhT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LC8PQRa1bZhT",
    "outputId": "0782f172-ccc1-442e-99bd-c9f6f6b31f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 87808)             89915392  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 87808)            351232    \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 87808)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 7, 256)      0         \n",
      "                                                                 \n",
      " conv3d_transpose (Conv3DTra  (None, 7, 7, 7, 128)     23887872  \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 7, 128)     512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 7, 7, 7, 128)      0         \n",
      "                                                                 \n",
      " conv3d_transpose_1 (Conv3DT  (None, 14, 14, 14, 64)   2809856   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 14, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 14, 14, 14, 64)    0         \n",
      "                                                                 \n",
      " conv3d_transpose_2 (Conv3DT  (None, 28, 28, 28, 32)   702464    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 28, 28, 28, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 28, 28, 28, 32)    0         \n",
      "                                                                 \n",
      " conv3d_transpose_3 (Conv3DT  (None, 56, 56, 56, 1)    4000      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " thresholded_re_lu (Threshol  (None, 56, 56, 56, 1)    0         \n",
      " dedReLU)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 117,671,712\n",
      "Trainable params: 117,495,648\n",
      "Non-trainable params: 176,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Y4p7cGfibWY4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4p7cGfibWY4",
    "outputId": "a9cbca2d-aa46-45a3-ceeb-e35168d17269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 28, 28, 28, 32)    4032      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 28, 28, 28, 32)    0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 28, 28, 32)    0         \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 14, 14, 14, 64)    256064    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 14, 14, 14, 64)    0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 14, 64)    0         \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 7, 7, 7, 128)      1024128   \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 7, 7, 7, 128)      0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 7, 7, 128)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 43904)             0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 43904)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 43905     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,328,129\n",
      "Trainable params: 1,328,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8zjUBXeNyWwW",
   "metadata": {
    "id": "8zjUBXeNyWwW"
   },
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0146049b",
   "metadata": {
    "id": "0146049b"
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "## Model Compile: Loss Function ##\n",
    "##################################\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True) # we take a BinaryCrossentropy\n",
    "\n",
    "# Binary cross entropy compares each of the predicted probabilities to actual class output which can be either 0 or 1\n",
    "# Binary Cross Entropy is the negative average of the log of corrected predicted probabilities\n",
    "\n",
    "########################\n",
    "## Discriminator loss ##\n",
    "########################\n",
    "\n",
    "# quantifies how well the discriminator is able to distinguish real images from generated \n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    # compares the predictions of the discriminator over real images to a matrix of [1s] | must have a tendency/likelihood to 1\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    # compares the predictions of the discriminator over generated images to a matrix of [0s] | must have a tendency/likelihood to 0\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss # Total loss\n",
    "\n",
    "####################\n",
    "## Generator loss ##\n",
    "####################\n",
    "\n",
    "# quantifies how well it was able to trick the discriminator, if the generator is performing well, the discriminator will classify the fake images as real (1). \n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    binary_cross_entropy = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    # the generator's output need to have a tendency to 1, We compare the discriminators decisions on the generated images to an array of [1s]\n",
    "    return binary_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I2aEX5qzyZ2x",
   "metadata": {
    "id": "I2aEX5qzyZ2x"
   },
   "source": [
    "# OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f479b47d",
   "metadata": {
    "id": "f479b47d"
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "## Model Compile: Optimizer ##\n",
    "##############################\n",
    "\n",
    "# Two different optimizers since we train two separate networks:\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4) # SGD INSTEAD???   (Radford et al., 2015)\n",
    "\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4) # SGD INSTEAD???  (Radford et al., 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8D7GfQNbdp9",
   "metadata": {
    "id": "f8D7GfQNbdp9"
   },
   "source": [
    "# CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9fb6755",
   "metadata": {
    "id": "b9fb6755"
   },
   "outputs": [],
   "source": [
    "######################\n",
    "## Save checkpoints ##\n",
    "######################\n",
    "\n",
    "# save and restore models, which can be helpful in case a long running training task is interrupted.\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 #discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator) #,\n",
    "                                 #discriminator=discriminator)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 #discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator) #,\n",
    "                                 #discriminator=discriminator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p49RDgftydc3",
   "metadata": {
    "id": "p49RDgftydc3"
   },
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "269e4fcb",
   "metadata": {
    "id": "269e4fcb"
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "\n",
    "####################\n",
    "## Training steps ##\n",
    "####################\n",
    "\n",
    "def train_step(images): # train for just ONE STEP aka one forward and back propagation\n",
    "\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim]) #tf.random.normal([BATCH_SIZE, noise_dim]) # generate the noises [batch size, latent space 100 dimention vector]\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: # get the gradient for each parameter for this step\n",
    "      generated_images = generator(noise, training=True) # iterates over the noises\n",
    "\n",
    "      real_output = discriminator(images, training=True) # trains discriminator based on labeled real pics\n",
    "      fake_output = discriminator(generated_images, training=True) # trains discriminator based on labeled generated pics\n",
    "    # why it doesnt traing all at ones\n",
    "\n",
    "      gen_loss = generator_loss(fake_output) # calculating the generator loss function previously defined\n",
    "      disc_loss = discriminator_loss(real_output, fake_output) # calculating the descrim loss function previously defined\n",
    "\n",
    "    print(f\"gen loss : {gen_loss}\")\n",
    "    print(f\"gen loss : {disc_loss}\")\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    # saving the gradients of each trainable variable of the generator\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    # saving the gradients of each trainable variable of the discriminator\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    # applying the gradients on the trainable variables of the generator to update the parameters\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    # applying the gradients on the trainable variables of the generator to update the parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7ca1f50",
   "metadata": {
    "id": "b7ca1f50"
   },
   "outputs": [],
   "source": [
    "###################\n",
    "## Training loop ##\n",
    "###################\n",
    "\n",
    "# training loop itself using train_step function previously defined \n",
    "\n",
    "def train(dataset, epochs):\n",
    "\n",
    "  # load checkpoint\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
    "    print(\"################################\")\n",
    "    \n",
    "    for index, image_batch in enumerate(dataset):\n",
    "        noise = tf.random.normal([BATCH_SIZE, noise_dim]) #tf.random.normal([BATCH_SIZE, noise_dim]) # generate the noises [batch size, latent space 100 dimention vector]\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: # get the gradient for each parameter for this step\n",
    "          generated_images = generator(noise, training=True) # iterates over the noises\n",
    "\n",
    "          real_output = discriminator(image_batch, training=True) # trains discriminator based on labeled real pics\n",
    "          fake_output = discriminator(generated_images, training=True) # trains discriminator based on labeled generated pics\n",
    "        # why it doesnt traing all at ones\n",
    "\n",
    "          gen_loss = generator_loss(fake_output) # calculating the generator loss function previously defined\n",
    "          disc_loss = discriminator_loss(real_output, fake_output) # calculating the descrim loss function previously defined\n",
    "        \n",
    "        if (index + 1) % 25 == 0:\n",
    "          print(f\"Minibatch Number {index+1}\")\n",
    "          print(f\"The loss of the generator is: {gen_loss}\") #, end=\"\\r\")\n",
    "          print(f\"The loss of the discriminator is: {disc_loss}\") #, end=\"\\r\")\n",
    "          print(\"################################\") #, end=\"\\r\")\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        # saving the gradients of each trainable variable of the generator\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "        # saving the gradients of each trainable variable of the discriminator\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        # applying the gradients on the trainable variables of the generator to update the parameters\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "        # applying the gradients on the trainable variables of the generator to update the parameters\n",
    "\n",
    "    # Produce images \n",
    "    display.clear_output(wait=True) # clearing output !!!TO BE CHECKED!!!\n",
    "    # generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "      os.chdir(\"/content/drive/MyDrive/data/volumetries\")\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix) # saving weights and biases previously calculated by the train step gradients\n",
    "    if (epoch + 1) % 5 == 0:  \n",
    "      generate_and_save_images(generator, epoch + 1, seed)\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  # generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Cmufe56Ix4_P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cmufe56Ix4_P",
    "outputId": "a6c1ee9a-59fe-4d7f-8afd-be027d823de3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 56, 56, 56, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = generator(seed, training=False)\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mqAtxrGcykXC",
   "metadata": {
    "id": "mqAtxrGcykXC"
   },
   "source": [
    "# GENERATE AND SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ee72031",
   "metadata": {
    "id": "5ee72031"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "## Generate and save images  ##\n",
    "###############################\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  os.chdir(\"/content/drive/MyDrive/data/volumetries/images\")\n",
    "\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(25, 25), facecolor = (STYLE), subplot_kw=dict(projection=\"3d\"))\n",
    "  \n",
    "  axes.voxels(predictions[0,:,:,:,0], facecolors=\"orange\", edgecolors=\"k\", linewidth=0.05)\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LjOUVeQ7bh4V",
   "metadata": {
    "id": "LjOUVeQ7bh4V"
   },
   "source": [
    "#TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "EJXM4_tOEKvk",
   "metadata": {
    "id": "EJXM4_tOEKvk"
   },
   "outputs": [],
   "source": [
    "if load_data:\n",
    "  os.chdir(\"/content/drive/MyDrive/data/volumetries\")\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices(raw_data[:4975]).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "else:\n",
    "  os.chdir(\"/content/drive/MyDrive/data/volumetries\")\n",
    "  raw_data = np.load(\"/content/drive/MyDrive/data/volumetries/raw-data-new.npy\")\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices(raw_data[:4975]).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb047de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feb047de",
    "outputId": "00915494-fe55-40ea-ba90-7b6245d15dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n",
      "################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch Number 25\n",
      "The loss of the generator is: 0.8391766548156738\n",
      "The loss of the discriminator is: 0.9114106893539429\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biljUKruvXux",
   "metadata": {
    "id": "biljUKruvXux"
   },
   "source": [
    "# ITERPOLATIONS & ANIMATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f0e14-c9c5-4bfe-8178-d24d2bc943f3",
   "metadata": {
    "id": "061f0e14-c9c5-4bfe-8178-d24d2bc943f3"
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(\"/content/drive/MyDrive/data/volumetries/images/training_checkpoints/ckpt-13.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AsQyS-gZkELj",
   "metadata": {
    "id": "AsQyS-gZkELj"
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal([2, 1, noise_dim]) # Random input vecto [number of samples, Width, Height]\n",
    "\n",
    "x = noise[0, 0, :].numpy()\n",
    "\n",
    "y = noise[1, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LYiPFEeCjxxK",
   "metadata": {
    "id": "LYiPFEeCjxxK"
   },
   "outputs": [],
   "source": [
    "# uniform interpolation between two points in latent space\n",
    "def interpolate_points(p1, p2, n_steps=100):\n",
    "\t# interpolate ratios between the points\n",
    "\tratios = np.linspace(0, 1, num=n_steps)\n",
    "\t# linear interpolate vectors\n",
    "\tvectors = list()\n",
    "\tfor ratio in ratios:\n",
    "\t\tv = (1.0 - ratio) * p1 + ratio * p2\n",
    "\t\tvectors.append(v)\n",
    "\treturn np.asarray(vectors)\n",
    " \n",
    "interpolation_result = interpolate_points(x, y, n_steps=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YqM2qlQAPuop",
   "metadata": {
    "id": "YqM2qlQAPuop"
   },
   "outputs": [],
   "source": [
    "interpolation_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dBSz-5mXg7tO",
   "metadata": {
    "id": "dBSz-5mXg7tO"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/MyDrive/data/volumetries/images\")\n",
    "\n",
    "count = 1\n",
    "\n",
    "for index, restult in enumerate(interpolation_result):\n",
    "  start = time.time()\n",
    "  print(f\"generating frame number {count}\")\n",
    "  fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(25, 25), facecolor = (STYLE), subplot_kw=dict(projection=\"3d\"))\n",
    "\n",
    "  for plot in range(1):\n",
    "    axes.voxels(generator(result[plot].reshape((1,512)), training=False)[0, :, :, :, 0], facecolors=\"orange\", edgecolors=\"k\", linewidth=0.05)\n",
    "    plt.savefig('image_interpolation_{:04d}.png'.format(count))\n",
    "  print ('Time for frame {} is {} sec'.format(index + 1, time.time()-start))\n",
    "  count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qgKJvEx_FL_l",
   "metadata": {
    "id": "qgKJvEx_FL_l"
   },
   "outputs": [],
   "source": [
    "# plt.plot(interpolation_result[:,0:1], result[:,1:2])\n",
    "\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12f19b-97bc-4082-b3ba-3ab044eee84c",
   "metadata": {
    "id": "ce12f19b-97bc-4082-b3ba-3ab044eee84c"
   },
   "outputs": [],
   "source": [
    "############################\n",
    "## Display a single image ##\n",
    "############################\n",
    "\n",
    "def display_image(epoch_no): # using the epoch number\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9a7fc-f519-4f38-b3dc-d3e3937789a7",
   "metadata": {
    "id": "b6f9a7fc-f519-4f38-b3dc-d3e3937789a7"
   },
   "outputs": [],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba846a83-1977-4c56-b0c7-d1231b120dea",
   "metadata": {
    "id": "ba846a83-1977-4c56-b0c7-d1231b120dea"
   },
   "outputs": [],
   "source": [
    "##################\n",
    "## Animated GIF ##\n",
    "##################\n",
    "\n",
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image_inter*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384d86f-6f77-41a1-ad9e-e6d115336bfc",
   "metadata": {
    "id": "1384d86f-6f77-41a1-ad9e-e6d115336bfc"
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_e6qHtKWFU0q",
   "metadata": {
    "id": "_e6qHtKWFU0q"
   },
   "source": [
    "# BONUS AND TRASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b01b97-502b-46cc-90e0-95a606027984",
   "metadata": {
    "id": "52b01b97-502b-46cc-90e0-95a606027984"
   },
   "outputs": [],
   "source": [
    "param_setters = dict()\n",
    "for var in tf.trainable_variables():\n",
    "    placeholder = tf.placeholder(var.dtype, var.shape, var.name.split(':')[0]+'_setter')\n",
    "    param_setters[var.name] = (tf.assign(var, placeholder), placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aL--gPJXofAZ",
   "metadata": {
    "id": "aL--gPJXofAZ"
   },
   "outputs": [],
   "source": [
    "generator.load_weights(\"/content/drive/MyDrive/data/volumetries/training_checkpoints/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocnMoli01Cw",
   "metadata": {
    "id": "rocnMoli01Cw"
   },
   "outputs": [],
   "source": [
    "# os.chdir(\"/content/drive/MyDrive/data/volumetries/training_checkpoints\")\n",
    "\n",
    "# reader = tf.train.load_checkpoint('/content/drive/MyDrive/data/volumetries/training_checkpoints/ckpt-19.data-00000-of-00001')\n",
    "# shape_from_key = reader.get_variable_to_shape_map()\n",
    "# dtype_from_key = reader.get_variable_to_dtype_map()\n",
    "\n",
    "# sorted(shape_from_key.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0Pi5sEek25hg",
   "metadata": {
    "id": "0Pi5sEek25hg"
   },
   "outputs": [],
   "source": [
    "# save_path = \"/content/drive/MyDrive/data/volumetries/training_checkpoints/ckpt-19.data-00000-of-00001\"\n",
    "\n",
    "# tf.train.Checkpoint.read(save_path=save_path, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NfufMcJsf2Tw",
   "metadata": {
    "id": "NfufMcJsf2Tw"
   },
   "outputs": [],
   "source": [
    "# with h5py.File('model.hdf5', 'w') as f:\n",
    "#     for var in tf.trainable_variables():\n",
    "#         key = var.name.replace('/', ' ')\n",
    "#         value = session.run(var)\n",
    "#         f.create_dataset(key, data=value)\n",
    "\n",
    "# tensor flow lo tiene como opcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vEymndXvfosU",
   "metadata": {
    "id": "vEymndXvfosU"
   },
   "outputs": [],
   "source": [
    "# with h5py.File('model.hdf5', 'w') as f:\n",
    "#     for var in tf.trainable_variables():\n",
    "#         key = var.name.replace('/', ' ')\n",
    "#         value = session.run(var)\n",
    "#         f.create_dataset(key, data=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6OM3eh3T4IkN",
   "metadata": {
    "id": "6OM3eh3T4IkN"
   },
   "outputs": [],
   "source": [
    "# checkpoint_path = \"training_1/cp.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "\n",
    "# # Train the model with the new callback\n",
    "# model.fit(train_images, \n",
    "#           train_labels,  \n",
    "#           epochs=10,\n",
    "#           validation_data=(test_images, test_labels),\n",
    "#           callbacks=[cp_callback])  # Pass callback to training\n",
    "\n",
    "# # This may generate warnings related to saving the state of the optimizer.\n",
    "# # These warnings (and similar warnings throughout this notebook)\n",
    "# # are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ovmJwXBrtkn0",
   "metadata": {
    "id": "ovmJwXBrtkn0"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import Model\n",
    "\n",
    "# MyGAN = Model(generator, discriminator)\n",
    "\n",
    "# MyGAN.load_weights(\"/content/drive/MyDrive/data/volumetries/training_checkpoints/ckpt-7.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oGEABn7VrAof",
   "metadata": {
    "id": "oGEABn7VrAof"
   },
   "outputs": [],
   "source": [
    "# # #get the latest checkpoint file\n",
    "# # checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# # latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "# latest=\"/content/drive/MyDrive/data/volumetries/training_checkpoints/ckpt-7.index\"\n",
    "\n",
    "# model_latest_checkpoint = make_three_dimentional_generator()\n",
    "# # Load the previously saved weights\n",
    "# model_latest_checkpoint.load_weights(latest)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "I2aEX5qzyZ2x",
    "f8D7GfQNbdp9",
    "mqAtxrGcykXC",
    "_e6qHtKWFU0q"
   ],
   "machine_shape": "hm",
   "name": "3d-dcgan-tensorflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
